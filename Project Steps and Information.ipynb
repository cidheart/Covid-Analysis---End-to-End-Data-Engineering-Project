{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "662a9b5c-bcc3-4208-bdbb-8fb2d78ea585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture-s3 to crawler to athena to glue to redshift to bi\n",
    "#enigma jhud-contains confirmed cases of covid \n",
    "#enigma nytimes-country and statewise data of us\n",
    "#testing-testing data\n",
    "#beds-hospital beds data\n",
    "#static-country codes,population,state abbrevation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5cc89-ec91-429c-93fc-15d554794cb2",
   "metadata": {},
   "source": [
    "Firstly we downloaded the dataset and uploaded it to our own bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739cd4a-febc-417d-828c-8d96f40792ea",
   "metadata": {},
   "source": [
    "Then we configured and created our crawler within AWS Athena and simulataneously creating our IAM role for the service we are using that is glue and do this process for all the data folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c4360-894a-43c3-a919-0ac12369b947",
   "metadata": {},
   "source": [
    "and through generate ddl in athena ( for storing the metadata of quesries of the athena, we should create a seperate bucket in s3) , we copied the schema and created data models (er models) and er stands for entity relationship on the draw.io website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bc708-190f-4ade-a6ab-d64fac9114c9",
   "metadata": {},
   "source": [
    "now write etl job in python and deploy to glue (after completition) under jobs to build star schema model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf51d970-9d57-43ef-9e64-73272d9146da",
   "metadata": {},
   "source": [
    "now save result to s3 in a binary format and build tables(schema) on redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ffafb-9d48-43a8-be89-17df880d3e64",
   "metadata": {},
   "source": [
    "then copy the data to redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1805792-bbe0-4197-acd0-9008b2939932",
   "metadata": {},
   "source": [
    "problem-state_datastate_abv column has its header in the values so we have to remove them and make them as headers, date format in the dimDate table and solved with the help of pandas to_datetime function,and glue doesn't support all python packages so we have to manually upload a s3 file for packages so that it will work in one of the job options where it will ask for the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798c51e-fd4b-4f53-89d1-aebb190c6bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
